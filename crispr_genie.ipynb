{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRISPRGenie\n",
    "\n",
    "This is the main notebook for the project *CRISPRGenie*. The current aim of the project is as follows:\n",
    "1. The input dataset contains **sgRNA** sequences for a total of 19k different genes from the human genome. \n",
    "2. The model will be trained on all the sequences to predict different possible sgRNA sequences based on the input target gene.\n",
    "3. The model will be autoregressive, i.e., it will predict new sequences based on its training data. Furthermore, the model will ideally contain a semi-supervised regression task which will allow the model to predict the metrics of the newly predicted sgRNA sequence/s for the given target.\n",
    "4. The metrics include the log2-fold changes and the effect (ranging from -9 to 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "The model training will take place in two steps:\n",
    "\n",
    "#### Part 1: Generating sgRNA Sequences\n",
    "\n",
    "**Model Design:**\n",
    "\n",
    "* Input: Gene symbol (e.g., ENSG00000148584)\n",
    "* Output: Set of sgRNA sequences\n",
    "\n",
    "**Approach:**\n",
    "\n",
    "* Data Preparation: For training, map each gene symbol to its corresponding sgRNA sequences. This could involve aggregating all sgRNA sequences that target a specific gene into a single training example.\n",
    "* Model Type: Use a generative model like GPT, which is adept at producing sequences. Train the model to generate sgRNA sequences when provided with a gene symbol.\n",
    "\n",
    "**Training:**\n",
    "\n",
    "* Input: Gene symbol.\n",
    "* Output: A sequence of sgRNAs or a concatenated string of multiple sgRNAs.\n",
    "Train the model to maximize the likelihood of generating correct sgRNA sequences given a gene symbol.\n",
    "\n",
    "#### Part 2: Predicting Effect Metrics\n",
    "\n",
    "**Model Design:**\n",
    "\n",
    "* Input: sgRNA sequence\n",
    "* Output: Effect metrics (quantized effect as an integer from -9 to 9)\n",
    "\n",
    "**Approach:**\n",
    "\n",
    "* Data Preparation: Use sgRNA sequences and their corresponding effect metrics from your dataset.\n",
    "* Model Type: A classification model (like BERT used for classification tasks) that can predict a class (effect metric) for each sgRNA sequence.\n",
    "\n",
    "**Training:**\n",
    "\n",
    "* Input: sgRNA sequence.\n",
    "* Output: Effect class.\n",
    "This model can be trained using a cross-entropy loss where each class corresponds to a different quantile of sgRNA efficacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "from transformers import GPT2Config, GPT2LMHeadModel, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>chr</th>\n",
       "      <th>strand</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>cellline</th>\n",
       "      <th>condition</th>\n",
       "      <th>sequence</th>\n",
       "      <th>symbol</th>\n",
       "      <th>ensg</th>\n",
       "      <th>log2fc</th>\n",
       "      <th>rc_initial</th>\n",
       "      <th>rc_final</th>\n",
       "      <th>effect</th>\n",
       "      <th>cas</th>\n",
       "      <th>screentype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50844073</td>\n",
       "      <td>50844096</td>\n",
       "      <td>10</td>\n",
       "      <td>+</td>\n",
       "      <td>26472758.0</td>\n",
       "      <td>Jiyoye</td>\n",
       "      <td>viability</td>\n",
       "      <td>GCAGCATCCCAACCAGGTGGAGG</td>\n",
       "      <td>A1CF</td>\n",
       "      <td>ENSG00000148584</td>\n",
       "      <td>0.315907</td>\n",
       "      <td>[260]</td>\n",
       "      <td>[244]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>hSpCas9</td>\n",
       "      <td>negative selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50814011</td>\n",
       "      <td>50814034</td>\n",
       "      <td>10</td>\n",
       "      <td>-</td>\n",
       "      <td>26472758.0</td>\n",
       "      <td>Jiyoye</td>\n",
       "      <td>viability</td>\n",
       "      <td>GCGGGAGTGAGAGGACTGGGCGG</td>\n",
       "      <td>A1CF</td>\n",
       "      <td>ENSG00000148584</td>\n",
       "      <td>2.144141</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[59]</td>\n",
       "      <td>9.0</td>\n",
       "      <td>hSpCas9</td>\n",
       "      <td>negative selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50836111</td>\n",
       "      <td>50836134</td>\n",
       "      <td>10</td>\n",
       "      <td>+</td>\n",
       "      <td>26472758.0</td>\n",
       "      <td>Jiyoye</td>\n",
       "      <td>viability</td>\n",
       "      <td>ATGACTCTCATACTCCACGAAGG</td>\n",
       "      <td>A1CF</td>\n",
       "      <td>ENSG00000148584</td>\n",
       "      <td>1.426034</td>\n",
       "      <td>[75]</td>\n",
       "      <td>[153]</td>\n",
       "      <td>8.0</td>\n",
       "      <td>hSpCas9</td>\n",
       "      <td>negative selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50836095</td>\n",
       "      <td>50836118</td>\n",
       "      <td>10</td>\n",
       "      <td>-</td>\n",
       "      <td>26472758.0</td>\n",
       "      <td>Jiyoye</td>\n",
       "      <td>viability</td>\n",
       "      <td>GAGTCATCGAGCAGCTGCCATGG</td>\n",
       "      <td>A1CF</td>\n",
       "      <td>ENSG00000148584</td>\n",
       "      <td>1.550133</td>\n",
       "      <td>[47]</td>\n",
       "      <td>[105]</td>\n",
       "      <td>8.0</td>\n",
       "      <td>hSpCas9</td>\n",
       "      <td>negative selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50816234</td>\n",
       "      <td>50816257</td>\n",
       "      <td>10</td>\n",
       "      <td>-</td>\n",
       "      <td>26472758.0</td>\n",
       "      <td>Jiyoye</td>\n",
       "      <td>viability</td>\n",
       "      <td>AGTCACCCTAGCAAAACCAGTGG</td>\n",
       "      <td>A1CF</td>\n",
       "      <td>ENSG00000148584</td>\n",
       "      <td>0.382513</td>\n",
       "      <td>[58]</td>\n",
       "      <td>[57]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>hSpCas9</td>\n",
       "      <td>negative selection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      start       end chr strand      pubmed cellline  condition  \\\n",
       "0  50844073  50844096  10      +  26472758.0   Jiyoye  viability   \n",
       "1  50814011  50814034  10      -  26472758.0   Jiyoye  viability   \n",
       "2  50836111  50836134  10      +  26472758.0   Jiyoye  viability   \n",
       "3  50836095  50836118  10      -  26472758.0   Jiyoye  viability   \n",
       "4  50816234  50816257  10      -  26472758.0   Jiyoye  viability   \n",
       "\n",
       "                  sequence symbol             ensg    log2fc rc_initial  \\\n",
       "0  GCAGCATCCCAACCAGGTGGAGG   A1CF  ENSG00000148584  0.315907      [260]   \n",
       "1  GCGGGAGTGAGAGGACTGGGCGG   A1CF  ENSG00000148584  2.144141       [17]   \n",
       "2  ATGACTCTCATACTCCACGAAGG   A1CF  ENSG00000148584  1.426034       [75]   \n",
       "3  GAGTCATCGAGCAGCTGCCATGG   A1CF  ENSG00000148584  1.550133       [47]   \n",
       "4  AGTCACCCTAGCAAAACCAGTGG   A1CF  ENSG00000148584  0.382513       [58]   \n",
       "\n",
       "  rc_final  effect      cas          screentype  \n",
       "0    [244]     2.0  hSpCas9  negative selection  \n",
       "1     [59]     9.0  hSpCas9  negative selection  \n",
       "2    [153]     8.0  hSpCas9  negative selection  \n",
       "3    [105]     8.0  hSpCas9  negative selection  \n",
       "4     [57]     3.0  hSpCas9  negative selection  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('GenomeCRISPR_full.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ensg</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000148584</td>\n",
       "      <td>GCAGCATCCCAACCAGGTGGAGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000148584</td>\n",
       "      <td>GCGGGAGTGAGAGGACTGGGCGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000148584</td>\n",
       "      <td>ATGACTCTCATACTCCACGAAGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000148584</td>\n",
       "      <td>GAGTCATCGAGCAGCTGCCATGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000148584</td>\n",
       "      <td>AGTCACCCTAGCAAAACCAGTGG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ensg                 sequence\n",
       "0  ENSG00000148584  GCAGCATCCCAACCAGGTGGAGG\n",
       "1  ENSG00000148584  GCGGGAGTGAGAGGACTGGGCGG\n",
       "2  ENSG00000148584  ATGACTCTCATACTCCACGAAGG\n",
       "3  ENSG00000148584  GAGTCATCGAGCAGCTGCCATGG\n",
       "4  ENSG00000148584  AGTCACCCTAGCAAAACCAGTGG"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract only the necessary columns\n",
    "data_relevant = df[['ensg', 'sequence']]\n",
    "\n",
    "# Drop any rows with missing values in these columns to ensure data integrity\n",
    "data_relevant = data_relevant.dropna()\n",
    "\n",
    "# take the first 1k instances as a test\n",
    "data_relevant = data_relevant[:1000]\n",
    "\n",
    "data_relevant.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization \n",
    "\n",
    "Since the current dataset has a much smaller vocabulary, I will be going with a custom tokenizer which will be lightweight compared to the pretrained tokenizer of GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenizer:\n",
    "    def __init__(self):\n",
    "        # Include all nucleotide bases, special tokens, and necessary characters for gene IDs\n",
    "        self.token_to_id = {\n",
    "            '[PAD]': 0, '[ID]': 1, '[SOS]': 2, '[EOS]': 3,\n",
    "            'A': 4, 'T': 5, 'G': 6, 'C': 7, \n",
    "            'E': 8, 'N': 9, 'S': 10, \n",
    "            '0': 11, '1': 12, '2': 13, '3': 14, '4': 15,\n",
    "            '5': 16, '6': 17, '7': 18, '8': 19, '9': 20\n",
    "        }\n",
    "        self.id_to_token = {v: k for k, v in self.token_to_id.items()}\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.token_to_id)\n",
    "\n",
    "    def encode(self, text):\n",
    "        \"\"\" Convert text to a list of token IDs, treating each character as a token unless enclosed in []. \"\"\"\n",
    "        tokens = []\n",
    "        i = 0\n",
    "        while i < len(text):\n",
    "            if text[i] == '[':  # Start of a special token\n",
    "                special_token_end = text.find(']', i)\n",
    "                if special_token_end != -1:\n",
    "                    tokens.append(text[i:special_token_end+1])\n",
    "                    i = special_token_end + 1\n",
    "                else:\n",
    "                    tokens.append(text[i])  # Fallback if ']' is missing\n",
    "                    i += 1\n",
    "            else:\n",
    "                tokens.append(text[i])\n",
    "                i += 1\n",
    "        return [self.token_to_id[token] for token in tokens if token in self.token_to_id]\n",
    "\n",
    "    def decode(self, token_ids):\n",
    "        \"\"\" Convert a list of token IDs back to a string. \"\"\"\n",
    "        return ''.join(self.id_to_token.get(token_id, '') for token_id in token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: [1, 8, 9, 10, 6, 11, 11, 11, 11, 11, 12, 15, 19, 16, 19, 15, 2, 6, 7, 4, 6, 7, 4, 5, 7, 7, 7, 4, 4, 7, 7, 4, 6, 6, 5, 6, 6, 4, 6, 6, 3]\n",
      "Decoded: [ID]ENSG00000148584[SOS]GCAGCATCCCAACCAGGTGGAGG[EOS]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = CustomTokenizer()\n",
    "# Example encoding\n",
    "encoded = tokenizer.encode(\"[ID]ENSG00000148584[SOS]GCAGCATCCCAACCAGGTGGAGG[EOS]\")\n",
    "decoded = tokenizer.decode(encoded)\n",
    "\n",
    "print(\"Encoded:\", encoded)\n",
    "print(\"Decoded:\", decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneSequenceDataset(Dataset):\n",
    "    def __init__(self, gene_ids, sequences, tokenizer):\n",
    "        self.gene_ids = gene_ids\n",
    "        self.sequences = sequences\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gene_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Form the full sequence with special tokens\n",
    "        full_sequence = f\"[ID]{self.gene_ids[idx]}[SOS]{self.sequences[idx]}[EOS]\"\n",
    "        tokenized_sequence = self.tokenizer.encode(full_sequence)\n",
    "        return torch.tensor(tokenized_sequence, dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch_padded = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0)\n",
    "    return batch_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  8,  9, 10,  6, 11, 11, 11, 11, 11, 12, 15, 19, 16, 19, 15,  2,  6,\n",
      "          7,  4,  6,  7,  4,  5,  7,  7,  7,  4,  4,  7,  7,  4,  6,  6,  5,  6,\n",
      "          6,  4,  6,  6,  3],\n",
      "        [ 1,  8,  9, 10,  6, 11, 11, 11, 11, 11, 12, 16, 16, 17, 16, 18,  2,  5,\n",
      "          5,  6,  7,  7,  6,  5,  7,  4,  6,  7,  5,  5,  6,  6,  6,  4,  6,  6,\n",
      "          3,  0,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "gene_ids = ['ENSG00000148584', 'ENSG00000155657']\n",
    "sequences = ['GCAGCATCCCAACCAGGTGGAGG', 'TTGCCGTCAGCTTGGGAGG']\n",
    "tokenizer = CustomTokenizer()  # Make sure your tokenizer is properly defined\n",
    "\n",
    "dataset = GeneSequenceDataset(gene_ids, sequences, tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=20, collate_fn=collate_fn)\n",
    "\n",
    "# Quick test to see a batch from DataLoader\n",
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janmejay/anaconda3/envs/torch/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(21, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=21, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the pretrained model\n",
    "vocab_size = len(tokenizer.token_to_id)\n",
    "config = GPT2Config.from_pretrained('gpt2', vocab_size=vocab_size)\n",
    "model = GPT2LMHeadModel(config)\n",
    "model.resize_token_embeddings(vocab_size)\n",
    "# Moving the model to the current device\n",
    "model.to(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the dataloader for the entire dataset\n",
    "gene_ids = data_relevant['ensg']\n",
    "sequences = data_relevant['sequence']\n",
    "dataset = GeneSequenceDataset(gene_ids, sequences, tokenizer)\n",
    "# Using the custom collate function\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janmejay/anaconda3/envs/torch/lib/python3.12/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def custom_loss(model_output, labels, tokenizer):\n",
    "    \n",
    "    outputs = model_output.logits\n",
    "\n",
    "    # Find indices of [SOS] and [EOS] tokens\n",
    "    sos_id = tokenizer.token_to_id['[SOS]']\n",
    "    eos_id = tokenizer.token_to_id['[EOS]']\n",
    "\n",
    "    loss = 0\n",
    "    batch_size = outputs.size(0)\n",
    "    for i in range(batch_size):\n",
    "        # Extract the sequence between [SOS] and [EOS]\n",
    "        start = (labels[i] == sos_id).nonzero(as_tuple=True)[0]\n",
    "        end = (labels[i] == eos_id).nonzero(as_tuple=True)[0]\n",
    "        if start.nelement() == 0 or end.nelement() == 0:\n",
    "            continue  # Skip if [SOS] or [EOS] not found\n",
    "        if start.item() >= end.item():\n",
    "            continue  # Ensure valid range\n",
    "        # Calculate loss only within the [SOS] and [EOS] range\n",
    "        relevant_outputs = outputs[i, start:end, :]\n",
    "        relevant_labels = labels[i, start:end]\n",
    "        loss += F.cross_entropy(relevant_outputs, relevant_labels, reduction='sum')\n",
    "    return loss / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, tokenizer, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            inputs, labels = batch[:, :-1], batch[:, 1:]  # Shifted for predicting the next token\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = custom_loss(outputs, labels, tokenizer)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch + 1}, Loss: {total_loss / len(dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 28.78814559173584\n",
      "Epoch 2, Loss: 26.91771062850952\n"
     ]
    }
   ],
   "source": [
    "train(model, dataloader, tokenizer, optimizer, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def generate_sgRNA_sequence(model, tokenizer, gene_id, max_length=20, num_sequences=5, device='cpu'):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        # Prepare the input with the gene ID and start token\n",
    "        input_tokens = f\"[ID]{gene_id}[SOS]\"\n",
    "        input_ids = tokenizer.encode(input_tokens)\n",
    "        \n",
    "        input_tensor = torch.tensor([input_ids], dtype=torch.long).to(device)\n",
    "\n",
    "        # Beam search parameters\n",
    "        beam_size = num_sequences\n",
    "        sequences = [[input_ids[:], 0]]  # List of [sequence, score]\n",
    "\n",
    "        for _ in range(max_length):  # Limit maximum generation length\n",
    "            all_candidates = []\n",
    "            for seq, score in sequences:\n",
    "                input_tensor = torch.tensor([seq], dtype=torch.long).to(device)\n",
    "                output = model(input_tensor)\n",
    "                predictions = output.logits[0, -1, :]  # Get logits for the last token\n",
    "                probs = F.softmax(predictions, dim=-1)\n",
    "                top_k_probs, top_k_ids = probs.topk(beam_size)  # Get top k probabilities and token IDs\n",
    "                \n",
    "                for i in range(beam_size):\n",
    "                    candidate = [seq + [top_k_ids[i].item()], score - torch.log(top_k_probs[i]).item()]\n",
    "                    all_candidates.append(candidate)\n",
    "\n",
    "            # Order all candidates by score\n",
    "            ordered = sorted(all_candidates, key=lambda x: x[1])\n",
    "            sequences = ordered[:beam_size]\n",
    "\n",
    "            # Stop if all sequences end with [EOS]\n",
    "            if all(tokenizer.token_to_id['[EOS]'] in seq for seq, score in sequences):\n",
    "                break\n",
    "\n",
    "        # Decode the top sequences\n",
    "        top_sequences = []\n",
    "        for seq, score in sequences:\n",
    "            if tokenizer.token_to_id['[EOS]'] in seq:\n",
    "                end_index = seq.index(tokenizer.token_to_id['[EOS]'])\n",
    "            else:\n",
    "                end_index = len(seq)\n",
    "            trimmed_seq = seq[len(input_ids):end_index]\n",
    "            generated_sequence = tokenizer.decode(trimmed_seq)\n",
    "            top_sequences.append(generated_sequence)\n",
    "\n",
    "        return top_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sgRNA Sequence: ['GGAGGAGAGAGAGAAAGCAG', 'GGAGGAGAGAGAGAAAGAGG', 'GAAGGAGAGAGAGAAAGCAG', 'GGAGGAGAGGAAGAAAGCAG', 'GGAGGAGAGAGAGAAAGGGG']\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "gene_id = \"ENSG00000148584\"\n",
    "generated_sgRNA = generate_sgRNA_sequence(model, tokenizer, gene_id)\n",
    "print(\"Generated sgRNA Sequence:\", generated_sgRNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
